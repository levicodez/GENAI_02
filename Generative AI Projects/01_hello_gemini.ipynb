{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-google-genai"
      ],
      "metadata": {
        "id": "eR9jAMsrqqZm",
        "outputId": "0359115b-f193-4543-ca7c-19dd5a2b66ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain_google_genai as genai"
      ],
      "metadata": {
        "id": "lwUmPj38vKMC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "P3KzwFMjvRyJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY:str = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "if GOOGLE_API_KEY:\n",
        "  print(\"GEMINI API FETCHED\")\n",
        "else:\n",
        "  print(\"GEMINI API NOT FETCHED\")"
      ],
      "metadata": {
        "id": "FCRAW2Gwvsnl",
        "outputId": "8964f16d-6b35-4f41-895c-54aaf7df2c65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEMINI API FETCHED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm:ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    api_key = GOOGLE_API_KEY,\n",
        ")"
      ],
      "metadata": {
        "id": "k5v-iQvGvcGt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response1 = llm.invoke(\"Tell me some jokes about the solo leveling anime. Use some emojies also\")"
      ],
      "metadata": {
        "id": "6jIikA_nyDeZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response1.content)"
      ],
      "metadata": {
        "id": "xS_4qQwByJlN",
        "outputId": "a52dd2cf-1363-491e-db05-26ffb8666a8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some jokes about the Solo Leveling anime, incorporating emojis:\n",
            "\n",
            "* Why did Sung Jin-Woo get a perfect score on his hunter exam? ğŸ¤” Because he solo'd the entire test! ğŸ’ªğŸ”¥\n",
            "\n",
            "* What's Sung Jin-Woo's favorite type of coffee? â˜•  Black coffee, because he doesn't need any *sugar*coating his victories! ğŸ˜\n",
            "\n",
            "* What do you call a group of Sung Jin-Woo's shadows? ğŸ‘¥  A *shadowy* conspiracy... to defeat all the monsters! ğŸ˜ˆğŸ‘»\n",
            "\n",
            "* Why did the ant queen refuse to fight Sung Jin-Woo? ğŸœğŸ‘‘ Because she heard he levels up *solo* and she didn't want to get *squashed*! ğŸ’¥ğŸœ\n",
            "\n",
            "* What's Sung Jin-Woo's least favorite thing about being the strongest hunter?  ğŸ˜´  Not having anyone to *level up* with!  (He's a bit lonely at the top.) ğŸ¥º\n",
            "\n",
            "\n",
            "*  Knock knock.\n",
            "   Who's there?\n",
            "   Sung Jin-Woo.\n",
            "   Sung Jin-Woo who?\n",
            "   Sung Jin-Woo's about to solo this whole joke! ğŸ˜‚ğŸ’ª\n",
            "\n",
            "\n",
            "Remember these are just lighthearted jokes.  The anime is full of intense action and serious moments! ğŸ˜Š\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "display(Markdown(response1.content))"
      ],
      "metadata": {
        "id": "EsAL7do60zno",
        "outputId": "f18d2f5a-1c9e-40a1-8d43-61a1722eeb90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here are some jokes about the Solo Leveling anime, incorporating emojis:\n\n* Why did Sung Jin-Woo get a perfect score on his hunter exam? ğŸ¤” Because he solo'd the entire test! ğŸ’ªğŸ”¥\n\n* What's Sung Jin-Woo's favorite type of coffee? â˜•  Black coffee, because he doesn't need any *sugar*coating his victories! ğŸ˜\n\n* What do you call a group of Sung Jin-Woo's shadows? ğŸ‘¥  A *shadowy* conspiracy... to defeat all the monsters! ğŸ˜ˆğŸ‘»\n\n* Why did the ant queen refuse to fight Sung Jin-Woo? ğŸœğŸ‘‘ Because she heard he levels up *solo* and she didn't want to get *squashed*! ğŸ’¥ğŸœ\n\n* What's Sung Jin-Woo's least favorite thing about being the strongest hunter?  ğŸ˜´  Not having anyone to *level up* with!  (He's a bit lonely at the top.) ğŸ¥º\n\n\n*  Knock knock.\n   Who's there?\n   Sung Jin-Woo.\n   Sung Jin-Woo who?\n   Sung Jin-Woo's about to solo this whole joke! ğŸ˜‚ğŸ’ª\n\n\nRemember these are just lighthearted jokes.  The anime is full of intense action and serious moments! ğŸ˜Š\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "aPvhT-ee1evl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"You are a helpful assistant. Answer the following question:\\n\\n{question}\"\n",
        ")"
      ],
      "metadata": {
        "id": "kelT8elw1Cul"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "Bv6hUgC11UTN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt_template)"
      ],
      "metadata": {
        "id": "ulVkIp9J1qwz",
        "outputId": "421a0d48-7a83-4cda-93d9-02a2cb1c33da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-4f9708b53e60>:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt_template)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "34wBqI3J1tXF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}